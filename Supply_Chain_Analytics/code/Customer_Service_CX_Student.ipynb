{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a576a53c",
   "metadata": {},
   "source": [
    "# Customer Service & Customer Experience Analytics (Student Version)\n",
    "\n",
    "This notebook supports the **Customer Service & Customer Experience** session using a ticket-level dataset.\n",
    "\n",
    "Constraints for this topic:\n",
    "Do not use OTIF, fill rate, or backorders.\n",
    "Focus on service interaction dynamics and customer perception.\n",
    "\n",
    "Deliverables you must produce:\n",
    "A clean KPI table with 5 experience KPIs\n",
    "Descriptive, Diagnostic, Predictive (system math), Prescriptive (decision rules) outputs\n",
    "A short managerial summary based on evidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19028694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7cd166",
   "metadata": {},
   "source": [
    "## 1) Load data\n",
    "\n",
    "Dataset: `customer_service_experience_tickets.csv`\n",
    "\n",
    "Expected grain:\n",
    "One row = one customer ticket (issue reported + service handling outcomes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset\n",
    "path = \"https://raw.githubusercontent.com/saikisri97/17_Hof_Lecture_Code_Pingo/refs/heads/main/Supply_Chain_Analytics/data/customer_service_experience_tickets.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# TODO: Parse time columns as datetimes\n",
    "time_cols = [\"Reported_Time\", \"First_Response_Time\", \"Resolution_Time\"]\n",
    "for c in time_cols:\n",
    "    df[c] = pd.to_datetime(df[c])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d189fda",
   "metadata": {},
   "source": [
    "## 2) Data dictionary (write your own)\n",
    "\n",
    "Task: Read the dataframe and understand what each column means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Read the columns of DataFrame and understand each meaning \n",
    "data_dict = pd.DataFrame([\n",
    "    (\"Ticket_ID\", \"Unique identifier of the customer service ticket\"),\n",
    "    (\"Reported_Time\", \"When the customer issue enters the service system (arrival time)\"),\n",
    "    (\"Issue_Type\", \"Customer-reported problem category that drives complexity and routing\"),\n",
    "    (\"Channel\", \"Contact channel; influences responsiveness expectations and handling style\"),\n",
    "    (\"Region\", \"Operational market; may reflect staffing coverage and language complexity\"),\n",
    "    (\"Customer_Segment\", \"B2C vs SMB vs Enterprise; influences priority and handling depth\"),\n",
    "    (\"Priority\", \"Service priority classification; should influence triage and escalation\"),\n",
    "    (\"Backlog_At_Report\", \"Estimated queue size (open work) when the ticket arrives\"),\n",
    "    (\"Response_Minutes\", \"Time from Reported_Time to First_Response_Time (speed of acknowledgment)\"),\n",
    "    (\"Resolution_Minutes\", \"Time from Reported_Time to Resolution_Time (time in system)\"),\n",
    "    (\"Escalation_Flag\", \"1 if ticket required higher tier handling; indicates complexity or failure\"),\n",
    "    (\"First_Contact_Resolution_Flag\", \"1 if resolved without follow-up; a proxy for process effectiveness\"),\n",
    "    (\"Repeat_Contact_Flag\", \"1 if the customer contacted again; indicates unresolved friction\"),\n",
    "    (\"Customer_Effort_Score\", \"1–7 score; higher means more effort for customer\"),\n",
    "    (\"CSAT_Score\", \"1–5 satisfaction score; outcome-oriented perception metric\"),\n",
    "    (\"Sentiment_Score\", \"Numeric sentiment proxy (-1 to +1); early warning for churn risk\"),\n",
    "    (\"Outcome\", \"Resolved/Partially/Unresolved; quality of closure\"),\n",
    "    (\"Team\", \"Owning service team; used for diagnostics and capacity planning\"),\n",
    "], columns=[\"Column\",\"Meaning\"])\n",
    "data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db20e84",
   "metadata": {},
   "source": [
    "## 3) Data quality checks\n",
    "\n",
    "Minimum checks:\n",
    "Missing values by column\n",
    "Duplicate Ticket_ID\n",
    "Logical checks:\n",
    "First_Response_Time >= Reported_Time\n",
    "Resolution_Time >= First_Response_Time\n",
    "Response_Minutes and Resolution_Minutes non-negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Missing values\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "missing.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b82e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Duplicate Ticket_ID\n",
    "df[\"Ticket_ID\"].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Logical time checks\n",
    "bad_response = (df[\"First_Response_Time\"] < df[\"Reported_Time\"]).sum()\n",
    "bad_resolution = (df[\"Resolution_Time\"] < df[\"First_Response_Time\"]).sum()\n",
    "bad_response, bad_resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0f8a2",
   "metadata": {},
   "source": [
    "## 4) KPI engineering (exactly 5 KPIs)\n",
    "\n",
    "You must compute these 5 KPIs :\n",
    "\n",
    "1) Average Response Time (minutes)\n",
    "2) First Contact Resolution Rate\n",
    "3) Mean Resolution Time (minutes)\n",
    "4) Average Customer Effort Score (CES)\n",
    "5) Complaint Recurrence Probability (repeat contact rate)\n",
    "\n",
    "Output format:\n",
    "A single table with KPI name, formula description, computed value, and managerial interpretation. Calculate the values and write what each values means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3719c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute KPI values\n",
    "avg_response = None\n",
    "fcr_rate = None\n",
    "mean_resolution = None\n",
    "avg_ces = None\n",
    "repeat_rate = None\n",
    "\n",
    "kpi_table = pd.DataFrame([\n",
    "    {\"KPI\": \"Average Response Time (min)\", \"Value\": avg_response, \"Interpretation\": \"Lower is better; sets perceived responsiveness and reduces anxiety early\"},\n",
    "    {\"KPI\": \"First Contact Resolution Rate\", \"Value\": fcr_rate, \"Interpretation\": \"\"},\n",
    "    {\"KPI\": \"Mean Resolution Time (min)\", \"Value\": mean_resolution, \"Interpretation\": \"\"},\n",
    "    {\"KPI\": \"Average Customer Effort Score (1-7)\", \"Value\": avg_ces, \"Interpretation\": \"\"},\n",
    "    {\"KPI\": \"Complaint Recurrence Probability\", \"Value\": repeat_rate, \"Interpretation\": \"\"},\n",
    "])\n",
    "\n",
    "kpi_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c804ea",
   "metadata": {},
   "source": [
    "## 5) Descriptive analytics: what is happening?\n",
    "\n",
    "Minimum outputs:\n",
    "Ticket volume trend by week\n",
    "Response time distribution (e.g., histogram)\n",
    "Resolution time by channel or priority (box plot or grouped summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Week column\n",
    "df[\"Week\"] = df[\"\"].dt.to_period(\"W\").astype(str)\n",
    "\n",
    "# TODO: Ticket volume by week\n",
    "weekly = df.groupby(\"\").size().reset_index(name=\"Tickets\")\n",
    "weekly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a55cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot weekly tickets\n",
    "plt.figure()\n",
    "plt.plot(weekly[\"Week\"], weekly[\"\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Ticket Volume by Week\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Tickets\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd86ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Response time histogram\n",
    "plt.figure()\n",
    "plt.hist(df[\"\"], bins=30)\n",
    "plt.title(\"Response Time Distribution (minutes)\")\n",
    "plt.xlabel(\"Response_Minutes\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3c157",
   "metadata": {},
   "source": [
    "## 6) Diagnostic analytics: why is it happening?\n",
    "\n",
    "Goal:\n",
    "Identify which drivers explain slow response and low FCR.\n",
    "\n",
    "Minimum analyses:\n",
    "Response_Minutes by Channel, Priority\n",
    "FCR rate by Issue_Type and by Team\n",
    "A simple correlation view for numeric drivers (Backlog_At_Report, Response_Minutes, Resolution_Minutes, CES, CSAT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Response by channel and priority (grouped summary)\n",
    "res_by = (df.groupby([\"\",\"\"])[\"Resolution_Minutes\"]\n",
    "          .agg([\"count\",\"mean\",\"median\"])\n",
    "          .reset_index()\n",
    "          .sort_values([\"Priority\",\"mean\"], ascending=[True, False]))\n",
    "res_by.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef09a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: FCR rate by issue type\n",
    "fcr_by_issue = (df.groupby(\"\")[\"First_Contact_Resolution_Flag\"]\n",
    "                 .mean()\n",
    "                 .sort_values())\n",
    "fcr_by_issue.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Correlation table on numeric columns\n",
    "num_cols = [\"Backlog_At_Report\",\"Response_Minutes\",\"Resolution_Minutes\",\"Handle_Minutes\",\"Customer_Effort_Score\",\"CSAT_Score\",\"Sentiment_Score\"]\n",
    "corr = df[num_cols].corr()\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac68f93",
   "metadata": {},
   "source": [
    "## 7) Predictive (Little Law): what happens if nothing changes?\n",
    "\n",
    "No ML forecasting models.\n",
    "\n",
    "Use system math:\n",
    "Little’s Law: L = λW\n",
    "\n",
    "Where:\n",
    "L = average backlog / WIP in the service system\n",
    "λ = arrival rate (tickets per hour)\n",
    "W = average time in system (hours) from Reported_Time to Resolution_Time\n",
    "\n",
    "Tasks:\n",
    "Compute λ and W from data\n",
    "Estimate implied L\n",
    "Then run a scenario:\n",
    "If arrivals increase by +15% (peak season), and capacity stays constant, what happens to W or L?\n",
    "Explain in business terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute arrival rate (tickets/hour) over the full period\n",
    "# Observation window\n",
    "t_min = df[\"Reported_Time\"].min()\n",
    "t_max = df[\"Reported_Time\"].max()\n",
    "obs_hours = (t_max - t_min).total_seconds() / 3600\n",
    "# Hint: lambda = total tickets / total hours in observation window\n",
    "lambda_per_hour = None\n",
    "\n",
    "# TODO: Compute average time in system in hours\n",
    "df[\"Time_In_System_Hours\"] = (df[\"Resolution_Time\"] - df[\"Reported_Time\"]).dt.total_seconds() / 3600\n",
    "W = df[\"\"].mean()\n",
    "\n",
    "# TODO: Little's Law implied backlog (calculate this)\n",
    "L = None\n",
    "\n",
    "lambda_per_hour, W, L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scenario: +15% arrivals, same capacity\n",
    "lambda2 = None\n",
    "\n",
    "# If L stays the same, what does W become?\n",
    "W2 = None\n",
    "\n",
    "# If W stays the same, what does L become?\n",
    "L2 = None\n",
    "\n",
    "(lambda2, W2, L2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05bfe9",
   "metadata": {},
   "source": [
    "## 8) Prescriptive: what should be done?\n",
    "\n",
    "Read through 3 decision rules that can be implemented as policy triggers, such as:\n",
    "\n",
    "Escalate if Priority is High/Critical AND Sentiment is negative AND Response_Minutes exceeds threshold\n",
    "Route Billing disputes to Billing team when backlog is above threshold\n",
    "Offer proactive update when Resolution_Minutes crosses a threshold (experience recovery)\n",
    "\n",
    "Task:\n",
    "Write the rules clearly. (Due to time limitation, I have implemented them for you.)\n",
    "Quantify thresholds from your own analysis (e.g., 75th percentile response time).\n",
    "Then estimate how many tickets would be impacted by each rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Choose thresholds using percentiles\n",
    "p75_resp = np.percentile(df[\"Response_Minutes\"], 75)\n",
    "p75_res = np.percentile(df[\"Resolution_Minutes\"], 75)\n",
    "p75_resp, p75_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a692b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Rule 1: Escalate early for high-impact risk signals\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Condition: Priority in {High, Critical} AND Sentiment negative AND Response above 75th percentile\u001b[39;00m\n\u001b[1;32m      3\u001b[0m rule1 \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mdf\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPriority\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCritical\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      5\u001b[0m     (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment_Score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.25\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      6\u001b[0m     (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse_Minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m p75_resp)\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m rule1_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(rule1\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Rule 2: Proactive status update trigger (experience recovery)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Condition: Resolution time already beyond 75th percentile OR backlog high at report\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Rule 1: Escalate early for high-impact risk signals\n",
    "# Condition: Priority in {High, Critical} AND Sentiment negative AND Response above 75th percentile\n",
    "rule1 = (\n",
    "    df[\"Priority\"].isin([\"High\",\"Critical\"]) &\n",
    "    (df[\"Sentiment_Score\"] < -0.25) &\n",
    "    (df[\"Response_Minutes\"] > p75_resp)\n",
    ")\n",
    "rule1_count = int(rule1.sum())\n",
    "\n",
    "# Rule 2: Proactive status update trigger (experience recovery)\n",
    "# Condition: Resolution time already beyond 75th percentile OR backlog high at report\n",
    "rule2 = (\n",
    "    (df[\"Resolution_Minutes\"] > p75_res) |\n",
    "    (df[\"Backlog_At_Report\"] > np.percentile(df[\"Backlog_At_Report\"], 80))\n",
    ")\n",
    "rule2_count = int(rule2.sum())\n",
    "\n",
    "# Rule 3: Route-to-specialist policy\n",
    "# Condition: Billing dispute OR Account access -> move to specialist team if not already there\n",
    "rule3 = df[\"Issue_Type\"].isin([\"Billing dispute\",\"Account access\"])\n",
    "rule3_count = int(rule3.sum())\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"Policy Rule\": \"R1 Escalate early for High/Critical + negative sentiment + slow response\",\n",
    "     \"Thresholds\": f\"Sentiment<-0.25 and Response>{int(p75_resp)} min\",\n",
    "     \"Tickets impacted\": rule1_count,\n",
    "     \"Managerial intent\": \"Protect churn risk by prioritizing empathy + speed for high-impact cases.\"},\n",
    "    {\"Policy Rule\": \"R2 Proactive update when resolution time/backlog is high\",\n",
    "     \"Thresholds\": f\"Resolution>{int(p75_res)} min or Backlog>80th pct\",\n",
    "     \"Tickets impacted\": rule2_count,\n",
    "     \"Managerial intent\": \"Reduce customer anxiety and repeat contacts through proactive communication.\"},\n",
    "    {\"Policy Rule\": \"R3 Specialist routing for Billing disputes & Account access\",\n",
    "     \"Thresholds\": \"Issue_Type in {Billing dispute, Account access}\",\n",
    "     \"Tickets impacted\": rule3_count,\n",
    "     \"Managerial intent\": \"Increase first-contact resolution by matching complexity to skill.\"},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756b172",
   "metadata": {},
   "source": [
    "## 9) Managerial wrap-up (short, evidence-based)\n",
    "\n",
    "Write 8–12 lines:\n",
    "What is happening\n",
    "Why it is happening\n",
    "What will happen in peak load if nothing changes (Little’s Law)\n",
    "What 2–3 policies you recommend\n",
    "\n",
    "Must reference your computed KPIs and one diagnostic finding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221cf390",
   "metadata": {},
   "source": [
    "_Write your wrap-up here._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
