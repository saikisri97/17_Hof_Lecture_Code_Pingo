{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d96cdc",
   "metadata": {},
   "source": [
    "# ✅ Sales & Demand Planning – Solution Notebook (Reference)\n",
    "\n",
    "This notebook contains one possible solution for the Sales & Demand Planning hands-on.\n",
    "It mirrors the **STEP 1A → 4B** structure in the student notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4995a",
   "metadata": {},
   "source": [
    "## 0. Imports & Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a917b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Sales_Units</th>\n",
       "      <th>Is_Promo</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>SKU_B</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>19.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>SKU_A</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>SKU_B</td>\n",
       "      <td>-25</td>\n",
       "      <td>1</td>\n",
       "      <td>14.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>SKU_B</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>19.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>SKU_B</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>19.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Week    SKU  Sales_Units  Is_Promo  Price\n",
       "0  2023-05-14  SKU_B          213         0  19.49\n",
       "1  2023-03-19  SKU_A          157         0  14.99\n",
       "2  2024-09-29  SKU_B          -25         1  14.49\n",
       "3  2024-01-21  SKU_B          197         0  19.49\n",
       "4  2023-11-19  SKU_B          187         0  19.49"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NOTE: adjust the filename if you use a different path\n",
    "df_raw = pd.read_csv('https://raw.githubusercontent.com/saikisri97/17_Hof_Lecture_Code_Pingo/refs/heads/main/Supply_Chain_Analytics/data/sales_demand_planning.csv')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169623f4",
   "metadata": {},
   "source": [
    "## 0.1 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f8fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_report(df):\n",
    "    print(df.isna().sum())\n",
    "\n",
    "def check_week_structure(df):\n",
    "    print('dtypes:\\n', df.dtypes)\n",
    "    if 'Week' in df.columns and 'SKU' in df.columns:\n",
    "        dup = df.duplicated(subset=['Week', 'SKU']).sum()\n",
    "        print('Duplicate (Week, SKU) rows:', dup)\n",
    "\n",
    "def check_anomalies(df):\n",
    "    if 'Sales_Units' in df.columns:\n",
    "        print('\\nNegative sales rows:')\n",
    "        print(df[df['Sales_Units'] < 0])\n",
    "    if 'Is_Promo' in df.columns and 'Sales_Units' in df.columns:\n",
    "        print('\\nTop promo spikes:')\n",
    "        print(df[df['Is_Promo'] == 1].sort_values('Sales_Units', ascending=False).head())\n",
    "\n",
    "def step_check(step_name, df):\n",
    "    print(f'--- {step_name} ---')\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc99bd2",
   "metadata": {},
   "source": [
    "## STEP 1A – SEE: Structural Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22f806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week            object\n",
      "SKU             object\n",
      "Sales_Units      int64\n",
      "Is_Promo         int64\n",
      "Price          float64\n",
      "dtype: object\n",
      "Shape: (206, 5)\n",
      "Week           0\n",
      "SKU            0\n",
      "Sales_Units    0\n",
      "Is_Promo       0\n",
      "Price          0\n",
      "dtype: int64\n",
      "dtypes:\n",
      " Week            object\n",
      "SKU             object\n",
      "Sales_Units      int64\n",
      "Is_Promo         int64\n",
      "Price          float64\n",
      "dtype: object\n",
      "Duplicate (Week, SKU) rows: 4\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.dtypes)\n",
    "print('Shape:', df_raw.shape)\n",
    "missing_report(df_raw)\n",
    "check_week_structure(df_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86de76",
   "metadata": {},
   "source": [
    "## STEP 1B – SEE: Anomaly Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c2235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     206.000000\n",
      "mean      189.961165\n",
      "std       104.782229\n",
      "min       -25.000000\n",
      "25%       149.250000\n",
      "50%       182.000000\n",
      "75%       207.000000\n",
      "max      1275.000000\n",
      "Name: Sales_Units, dtype: float64\n",
      "\n",
      "Negative sales rows:\n",
      "          Week    SKU  Sales_Units  Is_Promo  Price\n",
      "2   2024-09-29  SKU_B          -25         1  14.49\n",
      "30  2024-01-14  SKU_A           -5         0  14.99\n",
      "33  2023-04-23  SKU_B           -5         0  19.49\n",
      "\n",
      "Top promo spikes:\n",
      "           Week    SKU  Sales_Units  Is_Promo  Price\n",
      "130  2023-10-29  SKU_B         1275         1  14.49\n",
      "194  2024-07-07  SKU_A          975         1   9.99\n",
      "29   2024-03-24  SKU_B          316         1  14.49\n",
      "202  2023-02-19  SKU_B          304         1  14.49\n",
      "123  2024-05-19  SKU_B          303         1  14.49\n",
      "\n",
      "Price describe:\n",
      "count    206.000000\n",
      "mean      16.468155\n",
      "std        2.854309\n",
      "min        9.990000\n",
      "25%       14.990000\n",
      "50%       14.990000\n",
      "75%       19.490000\n",
      "max       19.490000\n",
      "Name: Price, dtype: float64\n",
      "\n",
      "Negative sales rows:\n",
      "          Week    SKU  Sales_Units  Is_Promo  Price\n",
      "2   2024-09-29  SKU_B          -25         1  14.49\n",
      "30  2024-01-14  SKU_A           -5         0  14.99\n",
      "33  2023-04-23  SKU_B           -5         0  19.49\n",
      "\n",
      "Top promo spikes:\n",
      "           Week    SKU  Sales_Units  Is_Promo  Price\n",
      "130  2023-10-29  SKU_B         1275         1  14.49\n",
      "194  2024-07-07  SKU_A          975         1   9.99\n",
      "29   2024-03-24  SKU_B          316         1  14.49\n",
      "202  2023-02-19  SKU_B          304         1  14.49\n",
      "123  2024-05-19  SKU_B          303         1  14.49\n"
     ]
    }
   ],
   "source": [
    "print(df_raw['Sales_Units'].describe())\n",
    "print('\\nNegative sales rows:')\n",
    "print(df_raw[df_raw['Sales_Units'] < 0])\n",
    "\n",
    "print('\\nTop promo spikes:')\n",
    "print(df_raw[df_raw['Is_Promo'] == 1].sort_values('Sales_Units', ascending=False).head())\n",
    "\n",
    "print('\\nPrice describe:')\n",
    "print(df_raw['Price'].describe())\n",
    "check_anomalies(df_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa48a8",
   "metadata": {},
   "source": [
    "## STEP 1C – SEE Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3211618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Week is stored as string and may contain invalid patterns\n",
      "- Some (Week, SKU) combinations are duplicated\n",
      "- Negative Sales_Units and extreme promo spikes exist\n",
      "- Prices show promo vs non-promo differences but may have gaps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "see_summary = '''\n",
    "- Week is stored as string and may contain invalid patterns\n",
    "- Some (Week, SKU) combinations are duplicated\n",
    "- Negative Sales_Units and extreme promo spikes exist\n",
    "- Prices show promo vs non-promo differences but may have gaps\n",
    "'''\n",
    "print(see_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbae1f2",
   "metadata": {},
   "source": [
    "## STEP 2A – TREAT: Fix Calendar & Missing Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee371c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2A_calendar_fixed ---\n",
      "     Week_dt    SKU  Sales_Units  Is_Promo  Price        Week\n",
      "0 2023-01-01  SKU_A        145.0       0.0  14.99  2023-01-01\n",
      "1 2023-01-08  SKU_A        141.0       0.0  14.99  2023-01-08\n",
      "2 2023-01-15  SKU_A        210.0       1.0   9.99  2023-01-15\n",
      "3 2023-01-22  SKU_A        163.0       0.0  14.99  2023-01-22\n",
      "4 2023-01-29  SKU_A        148.0       0.0  14.99  2023-01-29\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_raw.copy()\n",
    "df_clean['Week_dt'] = pd.to_datetime(df_clean['Week'], errors='coerce')\n",
    "df_clean = df_clean.dropna(subset=['Week_dt'])\n",
    "\n",
    "df_clean = df_clean.groupby(['SKU','Week_dt'], as_index=False).agg({\n",
    "    'Sales_Units': 'sum',\n",
    "    'Is_Promo': 'max',\n",
    "    'Price': 'mean'\n",
    "})\n",
    "\n",
    "full_weeks = pd.date_range(\n",
    "    df_clean['Week_dt'].min().normalize(),\n",
    "    df_clean['Week_dt'].max().normalize(),\n",
    "    freq='W-SUN'\n",
    ")\n",
    "\n",
    "df_list = []\n",
    "for sku, sub in df_clean.groupby('SKU'):\n",
    "    sub = sub.set_index('Week_dt').reindex(full_weeks)\n",
    "    sub['SKU'] = sku\n",
    "    df_list.append(sub)\n",
    "\n",
    "df_treat = pd.concat(df_list).reset_index().rename(columns={'index':'Week_dt'})\n",
    "df_treat['Week'] = df_treat['Week_dt'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "step_check('2A_calendar_fixed', df_treat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b1a55",
   "metadata": {},
   "source": [
    "## STEP 2B – TREAT: Fix Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65088ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2B_anomalies_fixed ---\n",
      "     Week_dt    SKU  Sales_Units  Is_Promo  Price        Week\n",
      "0 2023-01-01  SKU_A        145.0       0.0  14.99  2023-01-01\n",
      "1 2023-01-08  SKU_A        141.0       0.0  14.99  2023-01-08\n",
      "2 2023-01-15  SKU_A        210.0       1.0   9.99  2023-01-15\n",
      "3 2023-01-22  SKU_A        163.0       0.0  14.99  2023-01-22\n",
      "4 2023-01-29  SKU_A        148.0       0.0  14.99  2023-01-29\n"
     ]
    }
   ],
   "source": [
    "df_treat['Sales_Units'] = df_treat['Sales_Units'].fillna(0)\n",
    "df_treat.loc[df_treat['Sales_Units'] < 0, 'Sales_Units'] = 0\n",
    "\n",
    "for sku, sub in df_treat.groupby('SKU'):\n",
    "    mask = (df_treat['SKU'] == sku) & (df_treat['Is_Promo'] == 1)\n",
    "    cap = sub[sub['Is_Promo'] == 1]['Sales_Units'].quantile(0.99)\n",
    "    df_treat.loc[mask & (df_treat['Sales_Units'] > cap), 'Sales_Units'] = cap\n",
    "\n",
    "df_treat['Price'] = df_treat.groupby('SKU')['Price'].ffill().bfill()\n",
    "\n",
    "step_check('2B_anomalies_fixed', df_treat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e55614f",
   "metadata": {},
   "source": [
    "## STEP 2C – VERIFY after TREAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351622fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week_dt        0\n",
      "SKU            0\n",
      "Sales_Units    0\n",
      "Is_Promo       7\n",
      "Price          0\n",
      "Week           0\n",
      "dtype: int64\n",
      "dtypes:\n",
      " Week_dt        datetime64[ns]\n",
      "SKU                    object\n",
      "Sales_Units           float64\n",
      "Is_Promo              float64\n",
      "Price                 float64\n",
      "Week                   object\n",
      "dtype: object\n",
      "Duplicate (Week, SKU) rows: 0\n",
      "\n",
      "Negative sales rows:\n",
      "Empty DataFrame\n",
      "Columns: [Week_dt, SKU, Sales_Units, Is_Promo, Price, Week]\n",
      "Index: []\n",
      "\n",
      "Top promo spikes:\n",
      "       Week_dt    SKU  Sales_Units  Is_Promo  Price        Week\n",
      "147 2023-10-29  SKU_B      1140.74       1.0  14.49  2023-10-29\n",
      "79  2024-07-07  SKU_A       874.34       1.0   9.99  2024-07-07\n",
      "168 2024-03-24  SKU_B       316.00       1.0  14.49  2024-03-24\n",
      "111 2023-02-19  SKU_B       304.00       1.0  14.49  2023-02-19\n",
      "176 2024-05-19  SKU_B       303.00       1.0  14.49  2024-05-19\n"
     ]
    }
   ],
   "source": [
    "missing_report(df_treat)\n",
    "check_week_structure(df_treat)\n",
    "check_anomalies(df_treat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960cf6c2",
   "metadata": {},
   "source": [
    "## STEP 3A – Descriptive Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240fc38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mean         std  min      max\n",
      "SKU                                        \n",
      "SKU_A  163.955192   80.474425  0.0   874.34\n",
      "SKU_B  208.324423  112.392169  0.0  1140.74\n",
      "\n",
      "Promo vs non-promo average sales:\n",
      "Is_Promo         0.0      1.0\n",
      "SKU                          \n",
      "SKU_A     151.793103  256.356\n",
      "SKU_B     201.047619  318.516\n"
     ]
    }
   ],
   "source": [
    "desc_stats = df_treat.groupby('SKU')['Sales_Units'].agg(['mean','std','min','max'])\n",
    "print(desc_stats)\n",
    "\n",
    "promo_vs_non = df_treat.groupby(['SKU','Is_Promo'])['Sales_Units'].mean().unstack()\n",
    "print('\\nPromo vs non-promo average sales:')\n",
    "print(promo_vs_non)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bcf01",
   "metadata": {},
   "source": [
    "## STEP 3B – Diagnostic Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9518d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promo uplift (%):\n",
      "SKU\n",
      "SKU_A    68.885143\n",
      "SKU_B    58.428138\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "uplift = (promo_vs_non[1] - promo_vs_non[0]) / promo_vs_non[0] * 100\n",
    "print('Promo uplift (%):')\n",
    "print(uplift)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1122e9",
   "metadata": {},
   "source": [
    "## STEP 3C – Predictive Analytics (3-week Moving Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c442c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU SKU_A: MAPE=11.4%, Bias=-0.17\n",
      "SKU SKU_B: MAPE=17.6%, Bias=-3.77\n"
     ]
    }
   ],
   "source": [
    "df_ma_list = []\n",
    "for sku, sub in df_treat.groupby('SKU'):\n",
    "    sub = sub.sort_values('Week_dt').copy()\n",
    "    sub['SMA_3'] = sub['Sales_Units'].rolling(window=3).mean()\n",
    "    df_ma_list.append(sub)\n",
    "\n",
    "df_forecast_all = pd.concat(df_ma_list)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def bias(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(y_pred - y_true)\n",
    "\n",
    "for sku, sub in df_forecast_all.groupby('SKU'):\n",
    "    eval_sub = sub.dropna(subset=['SMA_3']).tail(20)\n",
    "    m = mape(eval_sub['Sales_Units'], eval_sub['SMA_3'])\n",
    "    b = bias(eval_sub['Sales_Units'], eval_sub['SMA_3'])\n",
    "    print(f'SKU {sku}: MAPE={m:.1f}%, Bias={b:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a581ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4076e8e3",
   "metadata": {},
   "source": [
    "## STEP 4A – Forecast Next Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c879aeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next week forecast (units):\n",
      "{'SKU_A': 150.33333333333334, 'SKU_B': 203.33333333333334}\n"
     ]
    }
   ],
   "source": [
    "next_week_forecast = {}\n",
    "for sku, sub in df_forecast_all.groupby('SKU'):\n",
    "    latest = sub.dropna(subset=['SMA_3']).sort_values('Week_dt').iloc[-1]\n",
    "    next_week_forecast[sku] = latest['SMA_3']\n",
    "\n",
    "print('Next week forecast (units):')\n",
    "print(next_week_forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c648a",
   "metadata": {},
   "source": [
    "## STEP 4B – Prescriptive: Replenishment Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8872e5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SKU_A': {'forecast': 150.33333333333334,\n",
       "  'weekly_std': 144.2608863776371,\n",
       "  'safety_stock': 238.0304625231012,\n",
       "  'ROP': 388.36379585643454,\n",
       "  'current_inventory': 150.33333333333334,\n",
       "  'order_quantity': 238.0304625231012},\n",
       " 'SKU_B': {'forecast': 203.33333333333334,\n",
       "  'weekly_std': 77.8089672506671,\n",
       "  'safety_stock': 128.3847959636007,\n",
       "  'ROP': 331.7181292969341,\n",
       "  'current_inventory': 203.33333333333334,\n",
       "  'order_quantity': 128.38479596360074}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_level_z = 1.65\n",
    "replenishment_plan = {}\n",
    "\n",
    "for sku, sub in df_treat.groupby('SKU'):\n",
    "    sub = sub.sort_values('Week_dt')\n",
    "    weekly_std = sub['Sales_Units'].tail(26).std()\n",
    "    forecast = next_week_forecast[sku]\n",
    "    safety_stock = service_level_z * weekly_std\n",
    "    rop = forecast + safety_stock\n",
    "    current_inventory = forecast  # simple assumption\n",
    "    order_qty = max(0, rop - current_inventory)\n",
    "    replenishment_plan[sku] = {\n",
    "        'forecast': forecast,\n",
    "        'weekly_std': weekly_std,\n",
    "        'safety_stock': safety_stock,\n",
    "        'ROP': rop,\n",
    "        'current_inventory': current_inventory,\n",
    "        'order_quantity': order_qty,\n",
    "    }\n",
    "\n",
    "replenishment_plan\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
